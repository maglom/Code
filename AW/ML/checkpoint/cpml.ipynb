{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Checkpoint Machine Learning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data prep\n",
    "\n",
    "1. Download and import the data, Heart failure: \n",
    "https://www.kaggle.com/andrewmvd/heart-failure-clinical-data \n",
    "Into python. \n",
    "At the link you can see a description of each column, as well as histograms. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.linear_model import LinearRegression, LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix\n",
    "\n",
    "df = pd.read_csv('heart_failure_clinical_records_dataset.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. We are only going to use the feature columns \n",
    "“DEATH_EVENT, time, age, high_blood_pressure, ejection_fraction, serum_creatinine, \n",
    "serum_sodium”. \n",
    "Extract them from the original dataframe. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df[['DEATH_EVENT', 'time', 'age', 'high_blood_pressure', 'ejection_fraction', 'serum_creatinine', 'serum_sodium']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. Create a new column called “age_text”, where the value is “low” for age<=56, “high” for age>= \n",
    "73 and “medium” for ages between. \n",
    "remove the age column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.loc[(df['age'] <= 56), 'age_text'] = 'low'  \n",
    "df.loc[(df['age'] >= 73), 'age_text'] = 'high'\n",
    "df.loc[(df['age'] > 56) & (df['age'] < 73), 'age_text'] = 'mid'  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4. Use the “from sklearn.preprocessing import OneHotEncoder” and do a one hot encoding of \n",
    "“age_text” and add the three columns to the dataframe with the names “age_text0, age_text1 \n",
    "and age_text2”. It is irrelevant which of the columns “low”, “medium” and “high” is placed in \n",
    "which column. Remove the “age_text” from the dataframe. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "hot_enc = OneHotEncoder()\n",
    "hot_enc.fit(df[['age_text']])\n",
    "exp_lvl_columns = hot_enc.transform(df[['age_text']]).toarray()\n",
    "df1 = pd.DataFrame(exp_lvl_columns, columns=['age_text0', 'age_text1', 'age_text2'])\n",
    "df = pd.concat([df, df1], axis=1)\n",
    "df.drop('age_text', axis=1, inplace=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " 5. Use one of “from sklearn.preprocessing import MinMaxScaler” or “from sklearn.preprocessing \n",
    "import StandardScaler” and scale the columns “ejection_fraction, serum_creatinine, \n",
    "serum_sodium”. \n",
    "Add the columns back to the dataframe with the column names “ejection_fraction_sc, \n",
    "serum_creatinine_sc, serum_sodium_sc”, and remove the columns “ejection_fraction, \n",
    "serum_creatinine, serum_sodium”. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "scaler.fit(df[['ejection_fraction', 'serum_creatinine', 'serum_sodium']])\n",
    "df[['ejection_fraction_sc', 'serum_creatinine_sc', 'serum_sodium_sc']] = scaler.transform(df[['ejection_fraction', 'serum_creatinine', 'serum_sodium']])\n",
    "df.drop(['ejection_fraction', 'serum_creatinine', 'serum_sodium'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "6. STRETCH: \n",
    "add more column and do the appropriate scaling for those columns, as well as add log scaling \n",
    "for any column where that seams desirable.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classification\n",
    "\n",
    "1. From the prepped dataset above, extract the column “DEATH_EVENT” as y, and “age_text0, \n",
    "age_text1, age_text2, high_blood_pressure, ejection_fraction_sc, serum_creatinine_sc, \n",
    "serum_sodium_sc” as X. \n",
    "use the “np.c_[ ]” to get X and y in numpy format ready for training. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = df['DEATH_EVENT']\n",
    "X = df[['age_text0', 'age_text1', 'age_text2', 'high_blood_pressure', 'ejection_fraction_sc', 'serum_creatinine_sc', 'serum_sodium_sc']]\n",
    "y = np.c_[y]\n",
    "X = np.c_[X]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Use the “from sklearn.model_selection import train_test_split” and split X and y into X_train, \n",
    "X_test, y_train and y_test. Using a 20% test data size. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. Train a logistic regression algorithm on the training data. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-11 {color: black;background-color: white;}#sk-container-id-11 pre{padding: 0;}#sk-container-id-11 div.sk-toggleable {background-color: white;}#sk-container-id-11 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-11 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-11 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-11 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-11 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-11 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-11 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-11 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-11 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-11 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-11 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-11 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-11 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-11 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-11 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-11 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-11 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-11 div.sk-item {position: relative;z-index: 1;}#sk-container-id-11 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-11 div.sk-item::before, #sk-container-id-11 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-11 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-11 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-11 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-11 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-11 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-11 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-11 div.sk-label-container {text-align: center;}#sk-container-id-11 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-11 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-11\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LogisticRegression()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-11\" type=\"checkbox\" checked><label for=\"sk-estimator-id-11\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LogisticRegression</label><div class=\"sk-toggleable__content\"><pre>LogisticRegression()</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "LogisticRegression()"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = LogisticRegression()\n",
    "y_train = np.reshape(y_train, 239)\n",
    "model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4. Make prediction using the training and test data, name the prediction variables y_train_pred \n",
    "and y_test_pred.  \n",
    "Create a y_test_pred_naive which has the same shape as y_test, but only predicts the most \n",
    "common label. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_pred = model.predict(X_train)\n",
    "y_test_pred = model.predict(X_test)\n",
    "y_test_pred_naive = np.zeros((60,1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5. Use “from sklearn.metrics import accuracy_score” and calculate the train, test, and test_naive \n",
    "accuracy. \n",
    "Also using “from sklearn.metrics import confustion_matrix” and print the train, test, and \n",
    "test_naive confusion matrix. \n",
    "What are your conclusion, is the model working well compared to the naive predictions? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The model is giving accuracy score of: \n",
      "y_train_acu = 0.7615062761506276\n",
      "y_test_acu = 0.7\n",
      "The naive prediction:\n",
      "y_naive_acu = 0.65\n",
      "\n",
      "\n",
      "The model is giving a confusion_matrix score of: \n",
      "y_train_acu:\n",
      "[[150  14]\n",
      " [ 43  32]]\n",
      "y_test_acu:\n",
      "[[37  2]\n",
      " [16  5]]\n",
      "The naive prediction:\n",
      "y_naive_acu:\n",
      "[[39  0]\n",
      " [21  0]]\n",
      "\n",
      "\n",
      "I would say this model is not much better than the naive predictions because the score of the naive prediction is \n",
      "sometimes better and sometimes just a little lower than the model\n"
     ]
    }
   ],
   "source": [
    "y_train_acu = accuracy_score(y_train, y_train_pred)\n",
    "y_test_acu = accuracy_score(y_test, y_test_pred)\n",
    "y_naive_acu = accuracy_score(y_test, y_test_pred_naive)\n",
    "\n",
    "print(f'''The model is giving accuracy score of: \n",
    "y_train_acu = {y_train_acu}\n",
    "y_test_acu = {y_test_acu}\n",
    "The naive prediction:\n",
    "y_naive_acu = {y_naive_acu}\n",
    "\n",
    "''')\n",
    "\n",
    "y_train_conf = confusion_matrix(y_train, y_train_pred)\n",
    "y_test_conf = confusion_matrix(y_test, y_test_pred)\n",
    "y_naive_conf = confusion_matrix(y_test, y_test_pred_naive)\n",
    "\n",
    "print(f'''The model is giving a confusion_matrix score of: \n",
    "y_train_acu:\n",
    "{y_train_conf}\n",
    "y_test_acu:\n",
    "{y_test_conf}\n",
    "The naive prediction:\n",
    "y_naive_acu:\n",
    "{y_naive_conf}\n",
    "\n",
    "\n",
    "I would say this model is not much better than the naive predictions because the score of the naive prediction is \n",
    "sometimes better and sometimes just a little lower than the model''')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "6. STRETCH: \n",
    "Try other models example k-nearest-neighbor, SVM. DecisionTrees, Xgboost, try \n",
    "hyperparameter tuning them. How good an accuracy are you able to get on the test data? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The model is giving accuracy score of: \n",
      "y_train_acu = 0.7824267782426778\n",
      "y_test_acu = 0.7333333333333333\n",
      "The naive prediction:\n",
      "y_naive_acu = 0.65\n",
      "\n",
      "\n",
      "The model is giving a confusion_matrix score of: \n",
      "y_train_acu:\n",
      "[[151  13]\n",
      " [ 39  36]]\n",
      "y_test_acu:\n",
      "[[37  2]\n",
      " [14  7]]\n",
      "The naive prediction:\n",
      "y_naive_acu:\n",
      "[[39  0]\n",
      " [21  0]]\n"
     ]
    }
   ],
   "source": [
    "model_k = KNeighborsRegressor(15)\n",
    "model_k.fit(X_train, y_train)\n",
    "y_test_pred_kneigh = model_k.predict(X_test)\n",
    "y_train_pred_kneigh = model_k.predict(X_train)\n",
    "\n",
    "y_test_pred_kneigh = y_test_pred_kneigh > 0.5\n",
    "y_test_pred_kneigh = y_test_pred_kneigh.astype(int)\n",
    "\n",
    "y_train_pred_kneigh = y_train_pred_kneigh > 0.5\n",
    "y_train_pred_kneigh = y_train_pred_kneigh.astype(int)\n",
    "\n",
    "y_train_acu = accuracy_score(y_train, y_train_pred_kneigh)\n",
    "y_test_acu = accuracy_score(y_test, y_test_pred_kneigh)\n",
    "y_naive_acu = accuracy_score(y_test, y_test_pred_naive)\n",
    "\n",
    "print(f'''The model is giving accuracy score of: \n",
    "y_train_acu = {y_train_acu}\n",
    "y_test_acu = {y_test_acu}\n",
    "The naive prediction:\n",
    "y_naive_acu = {y_naive_acu}\n",
    "\n",
    "''')\n",
    "\n",
    "y_train_conf = confusion_matrix(y_train, y_train_pred_kneigh)\n",
    "y_test_conf = confusion_matrix(y_test, y_test_pred_kneigh)\n",
    "y_naive_conf = confusion_matrix(y_test, y_test_pred_naive)\n",
    "\n",
    "print(f'''The model is giving a confusion_matrix score of: \n",
    "y_train_acu:\n",
    "{y_train_conf}\n",
    "y_test_acu:\n",
    "{y_test_conf}\n",
    "The naive prediction:\n",
    "y_naive_acu:\n",
    "{y_naive_conf}''')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. From the prepped dataset above extract all columns, but only the rows where “DEATH_EVENT” \n",
    "is True (or 1). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.loc[df['DEATH_EVENT'] == 1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. From the data with only death instances, extract the column “time” as y, and “age_text0, \n",
    "age_text1, age_text2, high_blood_pressure, ejection_fraction_sc, serum_creatinine_sc, \n",
    "serum_sodium_sc” as X. \n",
    "use the “np.c_[ ]” to get X and y in numpy format ready for training. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = np.c_[df['time']]\n",
    "X = np.c_[df[['age_text0', 'age_text1', 'age_text2', 'high_blood_pressure', 'ejection_fraction_sc', 'serum_creatinine_sc', 'serum_sodium_sc']]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. Use the “from sklearn.model_selection import train_test_split” and split X and y into X_train_r, \n",
    "X_test_r, y_train_r and y_test_r. Using a 20% test data size. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_r, X_test_r, y_train_r, y_test_r = train_test_split(X, y, test_size=0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4. Train a linear regression algorithm on the training data. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-12 {color: black;background-color: white;}#sk-container-id-12 pre{padding: 0;}#sk-container-id-12 div.sk-toggleable {background-color: white;}#sk-container-id-12 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-12 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-12 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-12 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-12 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-12 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-12 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-12 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-12 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-12 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-12 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-12 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-12 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-12 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-12 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-12 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-12 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-12 div.sk-item {position: relative;z-index: 1;}#sk-container-id-12 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-12 div.sk-item::before, #sk-container-id-12 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-12 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-12 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-12 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-12 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-12 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-12 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-12 div.sk-label-container {text-align: center;}#sk-container-id-12 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-12 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-12\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LinearRegression()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-12\" type=\"checkbox\" checked><label for=\"sk-estimator-id-12\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LinearRegression</label><div class=\"sk-toggleable__content\"><pre>LinearRegression()</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "LinearRegression()"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_reg = LinearRegression()\n",
    "model_reg.fit(X_train_r, y_train_r)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5. Make prediction using the training and test data, name the prediction variables y_train_pred_r \n",
    "and y_test_pred_r.  \n",
    "Create a y_test_pred_naive_r which has the same shape as y_test_r, but only predicts the \n",
    "average time for the patients who died. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_pred_r = model_reg.predict(X_train_r)\n",
    "y_test_pred_r = model_reg.predict(X_test_r)\n",
    "mean_train = np.mean(y_train_r) #litt usikker på om det blir riktig med snitt av hele datasettet men landet på at det er bedre å ta utgangspunkt i train-datasettet.\n",
    "y_test_pred_naive_r = np.full((20, 1), mean_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "7. Use “from sklearn.metrics import mean_square_error” and “from sklearn.metrics import \n",
    "mean_absolute_error” and calculate the train, test, and test_naive scores.  \n",
    "What are your conclusion, is the model working well compared to the naive predictions? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "mse_train = 3629.719409492769\n",
      "mse_test =  3439.6334213883697\n",
      "mse_naive = 3831.530644044321\n",
      "\n",
      "mae_train = 49.124773380222926\n",
      "mae_test =  45.51776333684391\n",
      "mae_naive = 47.84342105263159\n",
      "\n",
      "I would say the model is not much better than the naive predictions. \n",
      "The model does not consistently outperform the naive prediction, and when it does outperform it is not by a large value.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "mse_train = mean_squared_error(y_train_r, y_train_pred_r)\n",
    "mse_test = mean_squared_error(y_test_r, y_test_pred_r)\n",
    "mse_naive = mean_squared_error(y_test_r, y_test_pred_naive_r)\n",
    "\n",
    "mae_train = mean_absolute_error(y_train_r, y_train_pred_r)\n",
    "mae_test = mean_absolute_error(y_test_r, y_test_pred_r)\n",
    "mae_naive = mean_absolute_error(y_test_r, y_test_pred_naive_r)\n",
    "\n",
    "print(f'''\n",
    "mse_train = {mse_train}\n",
    "mse_test =  {mse_test}\n",
    "mse_naive = {mse_naive}\n",
    "\n",
    "mae_train = {mae_train}\n",
    "mae_test =  {mae_test}\n",
    "mae_naive = {mae_naive}\n",
    "\n",
    "I would say the model is not much better than the naive predictions. \n",
    "The model does not consistently outperform the naive prediction, and when it does outperform it is not by a large value.\n",
    "''')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "8. STRECH: \n",
    "Try other models example k-nearest-neighbor, SVM. DecisionTrees, Xgboost, try \n",
    "hyperparameter tuning them. How good an MSE and MAE are you able to get on the test data? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_kn = KNeighborsRegressor()\n",
    "model_kn.fit(X_train_r, y_train_r)\n",
    "y_train_pred_r_kneigh = model_kn.predict(X_train_r)\n",
    "y_test_pred_r_kneigh = model_kn.predict(X_test_r)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "mse_train = 3463.3589473684215\n",
      "mse_test =  4584.1\n",
      "mse_naive = 3831.530644044321\n",
      "\n",
      "mae_train = 45.97368421052632\n",
      "mae_test =  59.08\n",
      "mae_naive = 47.84342105263159\n",
      "\n"
     ]
    }
   ],
   "source": [
    "mse_train = mean_squared_error(y_train_r, y_train_pred_r_kneigh)\n",
    "mse_test = mean_squared_error(y_test_r, y_test_pred_r_kneigh)\n",
    "mse_naive = mean_squared_error(y_test_r, y_test_pred_naive_r)\n",
    "\n",
    "mae_train = mean_absolute_error(y_train_r, y_train_pred_r_kneigh)\n",
    "mae_test = mean_absolute_error(y_test_r, y_test_pred_r_kneigh)\n",
    "mae_naive = mean_absolute_error(y_test_r, y_test_pred_naive_r)\n",
    "\n",
    "print(f'''\n",
    "mse_train = {mse_train}\n",
    "mse_test =  {mse_test}\n",
    "mse_naive = {mse_naive}\n",
    "\n",
    "mae_train = {mae_train}\n",
    "mae_test =  {mae_test}\n",
    "mae_naive = {mae_naive}\n",
    "''')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.1 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "397704579725e15f5c7cb49fe5f0341eb7531c82d19f2c29d197e8b64ab5776b"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
